%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A template for Wiley article submissions.
% Developed by Overleaf. 
%
% Please note that whilst this template provides a 
% preview of the typeset manuscript for submission, it 
% will not necessarily be the final publication layout.
%
% Usage notes:
% The "blind" option will make anonymous all author, affiliation, correspondence and funding information.
% Use "num-refs" option for numerical citation and references style.
% Use "alpha-refs" option for author-year citation and references style.

% \documentclass[alpha-refs]{wiley-article}
\documentclass[num-refs]{wiley-article}

% Add additional packages here if required
\usepackage{siunitx}

% Update article type if known
\papertype{Original Article or Review?}
% Include section in journal if known, otherwise delete
\paperfield{Methods \& Resources}

\title{Batch effects in large-scale proteomics studies: diagnostics and correction}

% Include full author names and degrees, when required by the journal.
% Use the \authfn to add symbols for additional footnotes and present addresses, if any. Usually start with 1 for notes about author contributions; then continuing with 2 etc if any author has a different present address.
\author[1, 2, 3]{Jelena Čuklina}
\author[1]{Chloe Lee}
\author[1]{Evan G. Williams}
\author[1]{Tatjana Sajic}
\author[1\authfn{2}]{Ben C. Collins}
\author[3]{Maria Rodriguez-Martinez}
\author[2]{Varun Sharma}
\author[1, 4]{Patrick Pedrioli}
\author[1, 5]{Ruedi Aebersold}

% Include full affiliation details for all authors
\affil[1]{Institute of Molecular Systems Biology, ETH Zurich, Zurich, CH-8093, Switzerland}
\affil[2]{PhD Program in Systems Biology, University of Zurich and ETH Zurich, Zurich, CH-8057  Switzerland}
\affil[3]{IBM Zurich Research Laboratory, Rüschlikon, CH-8803, Switzerland}
\affil[4]{ETH Zürich, PHRT-MS, Zürich, Switzerland}
\affil[5]{Faculty of Science, University of Zurich, Zurich, Switzerland}

\corraddress{Ruedi Aebersold, Institute of Molecular Systems Biology, ETH Zurich, Zurich, CH-8093, Switzerland}
\corremail{aebersold@imsb.biol.ethz.ch}

\presentadd[\authfn{2}]{Department, Institution, City, State or Province, Postal Code, Country}

\fundinginfo{J.Č. was supported by funding from the European Union Horizon 2020 research and innovation program under grant agreement No 668858 and the Swiss State Secretariat for Education, Research and Innovation (SERI) under contract number 15.0324-2. P.P. was supported by SNF grant no. SNF IZLRZ3\_163911.}

% Include the name of the author that should appear in the running header
\runningauthor{Čuklina et al.}

\begin{document}

\maketitle

\begin{abstract}
Advances in mass spectrometry-based proteomics have significantly increased sample throughput and sample to sample reproducibility to a degree that large-scale studies consisting of hundreds of samples are becoming routine. Increased sample numbers, however, come at the price of introducing batch effects, that decrease the power to identify the underlying biological variance. 

Here, we present step-by-step workflow for batch effects analysis in proteomics. This workflow allows to assess batch effects in a given dataset, select appropriate methods for their adjustment and control the quality of this adjustment. Corresponding tools are freely accessible via the R package "proBatch".
In addition to a general workflow, we propose a new solution for gradual MS signal deterioration, which is a mass spectrometry specific bias. We investigate in depth batch-related missingness and the missing value imputation problem, as they affect batch effects adjustment and analysis.

We demonstrate the workflow on three large-scale proteomics datasets. Although applied to DIA proteomics, the principles described here are expected to be applicable to wide range of proteomic methods. The code, accompanying the analysis, is also available.


\keywords{Batch effects, Quantitative proteomics, Normalization}
\end{abstract}

\section{Introduction}

Advances in mass spectrometry based proteomics have significantly increased sample throughput and sample to sample reproducibility to a degree that large-scale studies consisting of hundreds of samples are becoming routine \cite{Williams:2016aa, Liu2015, Sajic2018, Okada2016, Collins2017}. This makes mass spectrometry (MS) a method of choice to study of physiological processes and diseases, as proteins constitute a large part of the molecular machinery and carry out cellular functions through coordinated activity of protein complexes and molecular pathways  \cite{Schubert2017}. Promising as it is, mass spectrometry derived quantitative measurements on thousands of proteins, can be affected by minuscule differences in sample preparation and data acquisition conditions, such as different technicians or reagent batches. This phenomenon, known as “batch effects” introduces cumulative error that reduces statistical power to detect true biological signal. In most severe cases, biological signal gets extremely correlated with technical variables, which subsequently leads to concerns about the validity of biological conclusions \cite{Leek:2010aa, Akey:2007aa, Baggerly:2004aa, Petricoin:2002aa}.

Batch effects are a problem affecting not only proteomics, but literally all quantitative measurement methods in biology. Many of the methods addressing batch effects in high-throughput biomedical data have been established by DNA microarray community. This has made such methods as hierarchical clustering, principal component analysis and quantile normalization part of a standard method toolkit. With advances in mass spectrometry and the growing number of samples profiling, the interest for the batch effects topic is also growing in the proteomics community \cite{Karpievitch2012, Chawade:2014aa, Valikangas2018, Gregori2012}. Despite a large number of publications reviewing the problem of batch effects \cite{Leek:2010aa, Lazar:2013aa, Luo2010, Chen:2011ac, Dillies:2013aa, Chawade:2014aa}, the terminology, related to it, remains confusing: for example, the distinction between normalization and batch effects correction is not always clear (see \textcolor{red}{\textbf{\hl{Box 1}}} for brief explanations of relevant terms). Moreover, each tool published is implemented independently, using different formats of data for input and output, making analyses cumbersome to combine into pipelines and thus prone to errors. Finally, it is often unclear, how to control the improvement of the data after the adjustment for the batch effects. Thus, we decided to summarize the best practices in the field into a step-by-step tutorial, stressing, where appropriate, the specifics of mass spectrometry-based proteomics.

Mass spectrometry methods in proteomics, both DDA and DIA, suffer from a number of problems, unknown to genomic technologies. First, there is the problem of peptide to protein inference \cite{Clough:2012aa, Teo:2015aa, Rosenberger2014a, Choi2014, Muntel:2019aa}. As protein quantities are inferred from the quantities of measured peptides or even fragment ions, there is a question, on which level should the data be corrected. Second, it is known that missing values in mass spectrometry are often associated with technical factors \cite{Karpievitch2012, Matafora2017}. Finally, particularly high sample numbers, typically order of hundred or more, may suffer from MS signal drift, that needs to be accounted for \cite{Luan2018, Shen2016}. We include the discussion of these problems, and suggest solutions in multiple sections of this tutorial.

To bring the workflow into a practical context, we use three large-scale studies to illustrate the corresponding steps. All datasets have been acquired using SWATH-MS technology. The considerations described here and the conceptual workflow, however, are generic and are also applicable to other mass spectrometry based proteomic methods. For the purpose of user friendliness, we implemented this protocol as an  R package “proBatch”, already available on Bioconductor, and supplement the case studies with the corresponding code using the package.

This paper is organized as follows: first, we provide a brief overview of the workflow and define key terms for each step.  Next, we describe the datasets, used to define and test the workflow. We then expand each step, using the largest of three datasets, Aging Mice Study, to illustrate the steps, and refer to other two datasets, when appropriate. We devote a specialized section to the problem of missing values in relation to batch effects and indicate the caution points related to missing value imputation. After that we describe the "proBatch" tool and finish the manuscript with discussion of generalizability of the principles described to other methods or data acquisition, in proteomics and beyond. In conclusion, we summarize the information provided in previous sections and outline the expected developments in batch effects research.

\section{Addressing batch effects: the workflow}

Batch effects can only be corrected if batch factors have been considered in experimental design, otherwise, the data can be biased beyond repair  \cite{Hu2005, Gilad2015}. At the stage of experimental design, the main goal is to prevent confounding of biological groups and technical factors, causing batch effects. Also, number of samples, ensuring sufficiently powered study has to be evaluated. For control of variability, replicates should be included into the study. Experimental design is a complex issue, spanning beyond the scope of this article, however, the reader can use previously published materials on the topic \cite{Oberg2009, Cuklina2020}. With careful experimental design, batch effects can be adjusted for, uncovering biological signal in the data.
\subsection{Workflow overview}
Most of the data, acquired with high-throughput technologies, including MS-proteomics, can not be used in statistical analysis or model learning directly. The procedure ensuring comparability of the samples is known as batch correction. This procedure can be separated into the sequence of steps, as shown in Figure~\ref{fig:batch_fig1_workflow} and explained in more detail below.  
\begin{figure}[bt]
	\center
	\includegraphics[width=6cm]{figures/Fig0_workflow_staircase}
	\caption[Batch effect correction workflow]
	{Batch effect processing workflow}
	\label{fig:batch_fig1_workflow}
\end{figure}

We suggest a five-step workflow to address batch effects in large-scale dataset. Initial assessment allows to evaluate whether batch effects are present in raw, unnormalized data and to select normalization procedure. Second, normalization brings all samples from the dataset to the common scale, typical methods of normalization being sample-wide quantile normalization and median normalization. Third step is diagnostics of batch effects in normalized data, with methods such as PCA, hierarchical clustering. This step determines whether further correction is required. If batch effects are still present in the data, a furter step of batch correction is required. Batch correction addresses feature-specific biases, commonly addresses with tools like ComBat \cite{Johnson:2007aa} or feature-specific mean/median centering. Finally, quality control ensures that the data has been improved by correction: biases have been reduces while meaningful signal has been retained. In the next sections, we discuss each step of the workflow in more detail, illustrating it with examples from three large-scale proteomic datasets.

\subsection{Data processing preceding the workflow} 
This workflow takes quantitative data matrix as an input. Thus, it is assumed that the workflow starts with the data matrix, for which peptide-spectrum matching, and FDR control are completed. We strongly suggest to perform the protein quantification after the batch effects correction, as this procedure alters the abundances of transition and peptide, and these abundances are critical for the protein quantity inference \cite{Clough:2012aa, Teo:2015aa}.  

Also, we suggest to keep all detected peptides, also non-proteotypic and the ones with multiple missing values. Keeping all measurements allows to better evaluate the distribution within each sample, which is critical for subsequent normalization and batch adjustment steps.

Data is assumed to be log-transformed, unless the variance stabilizing transformation \cite{Durbin2002} is used, as this normalization method has log-like transformation integrated into the normalization procedure.

\subsection{Adding Citations and a References List}

Please use a \verb|.bib| file to store your references. When using Overleaf to prepare your manuscript, you can upload a \verb|.bib| file or import your Mendeley, CiteULike or Zotero library directly as a \verb|.bib| file\footnote{see \url{https://www.overleaf.com/blog/184}}. You can then cite entries from it, like this: \cite{Gregori2012}. Just remember to specify a bibliography style, as well as the filename of the \verb|.bib|.

You can find a video tutorial here to learn more about BibTeX: \url{https://www.overleaf.com/help/97-how-to-include-a-bibliography-using-bibtex}.

This template provides two options for the citation and reference list style: 
\begin{description}
\item[Numerical style] Use \verb|\documentclass[...,num-refs]{wiley-article}|
\item[Author-year style] Use \verb|\documentclass[...,alpha-refs]{wiley-article}|
\end{description}

\subsubsection{Third Level Heading}
Supporting information will be included with the published article. For submission any supporting information should be supplied as separate files but referred to in the text.

Appendices will be published after the references. For submission they should be supplied as separate files but referred to in the text.

\paragraph{Fourth Level Heading}
% Here are examples of quotes and epigraphs.
\begin{quote}
The significant problems we have cannot be solved at the same level of thinking with which we created them.\endnote{Albert Einstein said this.}
\end{quote}

\begin{epigraph}{Albert Einstein}
Anyone who has never made a mistake has never tried anything new.
\end{epigraph}

\subparagraph{Fifth level heading}
Measurements should be given in SI or SI-derived units.
Chemical substances should be referred to by the generic name only. Trade names should not be used. Drugs should be referred to by their generic names. If proprietary drugs have been used in the study, refer to these by their generic name, mentioning the proprietary name, and the name and location of the manufacturer, in parentheses.

\begin{table}[bt]
\caption{This is a table. Tables should be self-contained and complement, but not duplicate, information contained in the text. They should be not be provided as images. Legends should be concise but comprehensive – the table, legend and footnotes must be understandable without reference to the text. All abbreviations must be defined in footnotes.}
\begin{threeparttable}
\begin{tabular}{lccrr}
\headrow
\thead{Variables} & \thead{JKL ($\boldsymbol{n=30}$)} & \thead{Control ($\boldsymbol{n=40}$)} & \thead{MN} & \thead{$\boldsymbol t$ (68)}\\
Age at testing & 38 & 58 & 504.48 & 58 ms\\
Age at testing & 38 & 58 & 504.48 & 58 ms\\
Age at testing & 38 & 58 & 504.48 & 58 ms\\
Age at testing & 38 & 58 & 504.48 & 58 ms\\
\hiderowcolors
stop alternating row colors from here onwards\\
Age at testing & 38 & 58 & 504.48 & 58 ms\\
Age at testing & 38 & 58 & 504.48 & 58 ms\\
\hline  % Please only put a hline at the end of the table
\end{tabular}

\begin{tablenotes}
\item JKL, just keep laughing; MN, merry noise.
\end{tablenotes}
\end{threeparttable}
\end{table}

\section*{acknowledgements}
Acknowledgements should include contributions from anyone who does not meet the criteria for authorship (for example, to recognize contributions from people who provided technical help, collation of data, writing assistance, acquisition of funding, or a department chairperson who provided general support), as well as any funding or other support information.

\section*{conflict of interest}
You may be asked to provide a conflict of interest statement during the submission process. Please check the journal's author guidelines for details on what to include in this section. Please ensure you liaise with all co-authors to confirm agreement with the final statement.

\printendnotes

% Submissions are not required to reflect the precise reference formatting of the journal (use of italics, bold etc.), however it is important that all key elements of each reference are included.
\bibliography{batch_references}

\graphicalabstract{example-image}{Please check the journal's author guidelines for whether a graphical abstract, key points, new findings, or other items are required for display in the Table of Contents.}

\end{document}
